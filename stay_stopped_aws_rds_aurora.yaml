---
AWSTemplateFormatVersion: "2010-09-09"

Description: |-
  Stop AWS RDS and Aurora databases after the forced 7th-day start.

  github.com/sqlxpert/stay-stopped-aws-rds-aurora GPLv3 Copyright Paul Marcelin

Parameters:

  PlaceholderSuggestedStackName:
    Type: String
    Default: "StayStoppedRdsAurora"

  PlaceholderHelp:
    Type: String
    Default: "github.com/sqlxpert/stay-stopped-aws-rds-aurora"

  Enable:
    Type: String
    Description: >-
      Whether to stop databases forcibly started after 7 days
    Default: "true"
    AllowedValues:
      - "false"
      - "true"

  FollowUntilStopped:
    Type: String
    Description: >-
      Whether to monitor after requesting that a database be stopped. The
      default, "true", provides an ERROR-level log entry or an error (dead
      letter) queue message if the stop request is not complete
      QueueMaxReceiveCount * QueueVisibilityTimeoutSecs (defaults of 160
      times and 540 seconds or 9 minutes give 24 hours) after AWS started the
      database. If someone starts the database manually after it enters
      "stopped" status but before the next and final retry, the database will
      be stopped another time. This window lasts QueueVisibilityTimeoutSecs
      (540 seconds or 9 minutes, by default) and occurs every 7th day, but at
      an unpredictable time of day. Changing the value to "false" eliminates
      the conflict window, at the expense of the completion monitoring.
    Default: "true"
    AllowedValues:
      - "false"
      - "true"

  PlaceholderAdvancedParameters:
    Type: String
    Default: ""
    AllowedValues:
      - ""

  Test:
    Type: String
    Description: >-
      Whether to add Aurora database cluster and RDS database instance
      non-forced start events for temporary testing, and relax the queue
      policy for the main SQS queue so that users can send, read, and delete
      messages, for example, using the AWS Console or the AWS ClI.
      Tip:
      Temporarily reducing QueueVisibilityTimeoutSecs and
      QueueMaxReceiveCount , and changing LogLevel to "INFO", also facilitates
      testing.
      WARNING:
      Setting this to "true" causes any Aurora database cluster or RDS
      database instance to be stopped as soon as it is started.
    Default: "false"
    AllowedValues:
      - "false"
      - "true"

  QueueVisibilityTimeoutSecs:
    Type: Number
    Description: >-
      How many seconds between attempts to stop a database. This must be
      greater than LambdaFnTimeoutSecs . The default, 540 seconds or 9
      minutes, allows a second stop attempt as late as possible within the
      10-minute minimum billing period after a database starts. Reduce for
      for testing.
    Default: 540

  QueueMaxReceiveCount:
    Type: Number
    Description: >-
      How many times to try stopping a database. This number multiplied by
      QueueVisibilityTimeoutSecs is the maximum time allowed for database
      operations (mainly starting and stopping); after that, no error is
      logged but the forced database start event is moved to the error queue.
      The default, 160 times, multiplied by the QueueVisibilityTimeoutSecs
      default, 540 seconds or 9 minutes, allows 24 hours.
    MinValue: 1
    Default: 160

  ErrorQueueMessageRetentionPeriodSecs:
    Type: Number
    Description: >-
      How many seconds to keep messages (in the error queue). This must be
      greater than QueueMaxReceiveCount * QueueVisibilityTimeoutSecs . For
      consistency, set this to LogRetentionInDays * 86400 or the next largest
      value allowed by both CloudWatch Logs and SQS. The default, 1209600 , is
      14 days. See MessageRetentionPeriod in
      https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_SetQueueAttributes.html#API_SetQueueAttributes_RequestParameters
    Default: 1209600

  QueueMessageBytesMax:
    Type: Number
    Description: >-
      The maximum number of bytes in a forced database start event and an AWS
      Lambda function trigger event. The default, 32768 bytes, is 32 KiB. See
      MaximumMessageSize in
      https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_CreateQueue.html#API_CreateQueue_RequestParameters
    Default: 32768

  SqsKmsKey:
    Type: String
    Description: >-
      If this is blank, default non-KMS SQS encryption applies. To use the
      AWS-managed key (which does not support key policy restrictions, or
      cross-region or cross-account usage), specify "alias/aws/sqs". To use a
      custom key, specify "ACCOUNT:key/KEY_ID". Whether the custom key is a
      single-region key, a multi-region key primary, or a multi-region key
      replica, it must be in the same region where you are creating this
      stack. Even if the custom key is in the same AWS account as this stack,
      you must update the key policy to allow usage by EventBridge and SQS.
      See
      https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-targets.html#targets-permissions
      and
      https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-key-management.html#compatibility-with-aws-services
      . For a StackSet, if you wish to use a custom key, it must be
      multi-region ("mrk-" prefix in the KEY_ID), and a replica (or the
      primary key itself) must exist in every target region.
    Default: ""

  LambdaFnReservedConcurrentExecutions:
    Type: Number
    Description: >-
      How many batches of database start events can definitely be processed in
      parallel. To decline access to AWS Lambda reserved concurrency, set this
      to -1. See
      https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html#configuration-concurrency-reserved
    MinValue: -1
    Default: -1

  LambdaFnMaximumConcurrency:
    Type: Number
    Description: >-
      How many batches of database start events may be processed in parallel.
      The minimum is 2. If you set LambdaFnReservedConcurrentExecutions to 2
      or more, make this no larger than LambdaFnReservedConcurrentExecutions.
      See
      https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-scaling.html#events-sqs-max-concurrency
    MinValue: 2
    Default: 2

  LambdaFnRoleAttachLocalPolicyName:
    Type: String
    Description: >-
      The name of a customer-managed IAM policy to attach to the function
      role. By including "Effect": "Deny" statements, you could, for example,
      prevent the function from ever stopping production databases.
      Specify only the name, not the ARN.
      For a StackSet, the policy must exist, and have exactly the same name,
      in every target AWS account.
      Policies are account-wide, not regional.
    Default: ""

  LambdaFnBatchSize:
    Type: Number
    Description: >-
      How many database start events to process in a single invokation.
      Batching is not important for a sporadic and low-volume workload. If you
      change this, consider QueueMessageBytesMax , LambdaFnMemoryMB and
      LambdaFnTimeoutSecs .
    MinValue: 1
    Default: 2

  LambdaFnMemoryMB:
    Type: Number
    Description: >-
      How many megabytes of memory to allocate. Increase this only in case of
      out-of-memory errors.
    Default: 128

  LambdaFnTimeoutSecs:
    Type: Number
    Description: >-
      How many seconds before execution is canceled. Increase this only in
      case of time-out errors.
    Default: 30

  LogRetentionInDays:
    Type: Number
    Description: >-
      How many days to keep log entries. Because AWS starts stopped RDS and
      Aurora databases after 7 days, set this to the next largest allowed
      value to preserve information about the previous round of database
      start events. See retentionInDays in
      https://docs.aws.amazon.com/AmazonCloudWatchLogs/latest/APIReference/API_PutRetentionPolicy.html#API_PutRetentionPolicy_RequestParameters
    Default: 14

  LogLevel:
    Type: String
    Description: >-
      The level of detail in the log. See
      https://docs.python.org/3/library/logging.html#levels
    Default: ERROR
    AllowedValues:
      - CRITICAL
      - ERROR
      - WARNING
      - INFO
      - DEBUG
      - NOTSET

  CloudWatchLogsKmsKey:
    Type: String
    Description: >-
      If this is blank, default non-KMS CloudWatch Logs encryption applies. To
      use a KMS key, which must be a custom key, specify "ACCOUNT:key/KEY_ID".
      Whether the custom key is a single-region key, a multi-region key
      primary, or a multi-region key replica, it must be in the same region
      where you are creating this stack. Even if the custom key is in the same
      AWS account as this stack, you must update the key policy to allow usage
      by CloudWatch Logs. See
      https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/encrypt-log-data-kms.html#cmk-permissions
      . For a StackSet, the custom key must be multi-region ("mrk-" prefix in
      the KEY_ID), and a replica (or the primary key itself) must exist in
      every target region.
    Default: ""

Metadata:

  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: For Reference
        Parameters:
          - PlaceholderSuggestedStackName
          - PlaceholderHelp
      - Label:
          default: Essential
        Parameters:
          - Enable
          - FollowUntilStopped
      - Label:
          default: Advanced...
        Parameters:
          - PlaceholderAdvancedParameters
      - Label:
          default: Testing
        Parameters:
          - Test
      - Label:
          default: SQS queues for forced database start events and errors
        Parameters:
          - QueueVisibilityTimeoutSecs
          - QueueMaxReceiveCount
          - ErrorQueueMessageRetentionPeriodSecs
          - QueueMessageBytesMax
          - SqsKmsKey
      - Label:
          default: AWS Lambda function to stop databases
        Parameters:
          - LambdaFnReservedConcurrentExecutions
          - LambdaFnMaximumConcurrency
          - LambdaFnRoleAttachLocalPolicyName
          - LambdaFnBatchSize
          - LambdaFnMemoryMB
          - LambdaFnTimeoutSecs
      - Label:
          default: CloudWatch log for AWS Lambda function
        Parameters:
          - LogRetentionInDays
          - LogLevel
          - CloudWatchLogsKmsKey
    ParameterLabels:
      PlaceholderHelp:
        default: For help with this stack, see
      PlaceholderSuggestedStackName:
        default: Suggested stack name
      Enable:
        default: Enable?
      FollowUntilStopped:
        default: Follow the database after a stop request?
      PlaceholderAdvancedParameters:
        default: Do not change the parameters below, unless necessary!
      Test:
        default: Test mode?
      QueueVisibilityTimeoutSecs:
        default: Seconds between attempts to stop a database
      QueueMaxReceiveCount:
        default: How many times to try stopping a database
      ErrorQueueMessageRetentionPeriodSecs:
        default: Seconds before deleting a message
      QueueMessageBytesMax:
        default: Maximum bytes in a message
      SqsKmsKey:
        default: KMS encryption key
      LambdaFnReservedConcurrentExecutions:
        default: Number of reserved parallel operations
      LambdaFnMaximumConcurrency:
        default: Maximum number of parallel operations
      LambdaFnRoleAttachLocalPolicyName:
        default: Name of local IAM policy to attach to role
      LambdaFnBatchSize:
        default: Batch size
      LambdaFnMemoryMB:
        default: Megabytes of memory
      LambdaFnTimeoutSecs:
        default: Seconds before timeout
      LogRetentionInDays:
        default: Days before deleting
      LogLevel:
        default: Level of detail
      CloudWatchLogsKmsKey:
        default: KMS encryption key

Conditions:

  EnableTrue: !Equals [ !Ref Enable, "true" ]

  FollowUntilStoppedTrue: !Equals [ !Ref FollowUntilStopped, "true" ]

  TestTrue: !Equals [ !Ref Test, "true" ]

  SqsKmsKeyBlank: !Equals [ !Ref SqsKmsKey, "" ]
  SqsKmsKeyCustom:
    Fn::And:
      - !Not [ !Condition SqsKmsKeyBlank ]
      - !Not [ !Equals [ !Ref SqsKmsKey, "alias/aws/sqs" ] ]

  LambdaFnRoleAttachLocalPolicyNameBlank:
    !Equals [ !Ref LambdaFnRoleAttachLocalPolicyName, "" ]

  LambdaFnReservedConcurrentExecutionsOff:
    !Equals [ !Ref LambdaFnReservedConcurrentExecutions, -1 ]

  CloudWatchLogsKmsKeyBlank: !Equals [ !Ref CloudWatchLogsKmsKey, "" ]

Resources:

  # Administrator: Restrict iam:PassRole to prevent use with arbitrary AWS
  # Lambda functions.
  LambdaFnRole:
    Type: AWS::IAM::Role
    Properties:
      Description: !Sub "For ${AWS::Region} region"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal: { Service: lambda.amazonaws.com }
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - Fn::If:
            - LambdaFnRoleAttachLocalPolicyNameBlank
            - !Ref AWS::NoValue
            - !Sub "arn:${AWS::Partition}:iam::${AWS::AccountId}:policy/${LambdaFnRoleAttachLocalPolicyName}"
      Policies:

        # In-line policies apply only to one role, which can only be assumed
        # by AWS Lambda functions. Separate, "managed" policies could be
        # attached to other roles or users, allowing permission escalation.

        - PolicyName: CloudWatchLogsCreateLogGroupIfDeleted
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                Resource: !GetAtt LambdaFnLogGrp.Arn

        - PolicyName: CloudWatchLogsWrite
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:${LambdaFnLogGrp}:log-stream:*"
                # !GetAtt LogGroup.Arn ends with :* instead of allowing us to
                # append :log-stream:* to make a log stream ARN

        - PolicyName: RdsRead
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - rds:DescribeDBInstances
                  - rds:DescribeDBClusters
                Resource: "*"
              - Effect: Allow
                Action: rds:ListTagsForResource
                Resource:
                  - !Sub "arn:${AWS::Partition}:rds:${AWS::Region}:${AWS::AccountId}:db:*"
                  - !Sub "arn:${AWS::Partition}:rds:${AWS::Region}:${AWS::AccountId}:cluster:*"

        - PolicyName: RdsWrite
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - rds:StopDBInstance
                  - rds:StopDBCluster
                Resource:
                  - !Sub "arn:${AWS::Partition}:rds:${AWS::Region}:${AWS::AccountId}:db:*"
                  - !Sub "arn:${AWS::Partition}:rds:${AWS::Region}:${AWS::AccountId}:cluster:*"

        - Fn::If:
            - SqsKmsKeyCustom
            - PolicyName: SqsKmsDecryptNoteComplementsQueuePolicy
              PolicyDocument:
                Version: "2012-10-17"
                Statement:
                  - Effect: Allow
                    Action:
                      # https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-key-management.html#receive-from-encrypted-queue
                      - kms:Decrypt
                    Resource: !Sub "arn:${AWS::Partition}:kms:${AWS::Region}:${SqsKmsKey}"
                    Condition:
                      StringEquals: { "kms:ViaService": !Sub "sqs.${AWS::Region}.amazonaws.com" }
            - !Ref AWS::NoValue

  MainQueuePol:
    Type: AWS::SQS::QueuePolicy
    Properties:
      Queues: [ !Ref MainQueue ]
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Sid: RequireTls
            Effect: Deny
            Principal: "*"
            Action: sqs:*
            Resource: "*"
            Condition:
              Bool: { aws:SecureTransport: "false" }
          - Effect: Allow
            Principal: "*"
            Action: sqs:GetQueueAttributes
            Resource: "*"
          - Sid:
              Fn::If:
                - SqsKmsKeyCustom
                - SourceEventRulesNoteKeyPolicyNeedsEventBridgeSqsKmsEncrypt
                - SourceEventRules
            Effect: Allow
            Principal: { Service: events.amazonaws.com }
            Action: sqs:SendMessage
            Resource: "*"
            Condition:
              ArnEquals:
                "aws:SourceArn":
                  - !GetAtt AuroraDbForcedStartToMainQueueRule.Arn
                  - !GetAtt RdsDbForcedStartToMainQueueRule.Arn

          - Fn::If:
              - TestTrue
              - !Ref AWS::NoValue
              - Sid: ExclusiveSource
                Effect: Deny
                Principal: "*"
                Action: sqs:SendMessage
                Resource: "*"
                Condition:
                  ArnNotEquals:
                    "aws:SourceArn":
                      - !GetAtt AuroraDbForcedStartToMainQueueRule.Arn
                      - !GetAtt RdsDbForcedStartToMainQueueRule.Arn

          - Sid:
              Fn::If:
                - SqsKmsKeyCustom
                - TargetLambdaFnRoleNoteNeedsSqsKmsDecrypt
                - TargetLambdaFnRole
            Effect: Allow
            Principal: "*"
            Action:
              - sqs:ChangeMessageVisibility
              - sqs:ReceiveMessage
              - sqs:DeleteMessage
            Resource: "*"
            Condition:
              ArnEquals: { aws:PrincipalArn: !GetAtt LambdaFnRole.Arn }
          - Sid:
              Fn::If:
                - SqsKmsKeyCustom
                - TargetDeadLetterQueueNoteKeyPolicyNeedsSqsKmsDecrypt
                - TargetDeadLetterQueue
            Effect: Allow
            Principal: "*"
            Action:
              - sqs:ChangeMessageVisibility
              - sqs:ReceiveMessage
              - sqs:DeleteMessage
            Resource: "*"
            Condition:
              ArnEquals: { aws:SourceArn: !GetAtt ErrorQueue.Arn }

          - Fn::If:
              - TestTrue
              - !Ref AWS::NoValue
              - Sid: ExclusiveTargets
                Effect: Deny
                Principal: "*"
                Action:
                  - sqs:ChangeMessageVisibility
                  - sqs:ReceiveMessage
                  - sqs:DeleteMessage
                Resource: "*"
                Condition:
                  ArnNotEquals:
                    aws:PrincipalArn:
                      - !GetAtt LambdaFnRole.Arn
                    aws:SourceArn:
                      - !GetAtt ErrorQueue.Arn

  ErrorQueuePol:
    Type: AWS::SQS::QueuePolicy
    Properties:
      Queues: [ !Ref ErrorQueue ]
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Sid: RequireTls
            Effect: Deny
            Principal: "*"
            Action: sqs:*
            Resource: "*"
            Condition:
              Bool: { aws:SecureTransport: "false" }
          - Effect: Allow
            Principal: "*"
            Action: sqs:GetQueueAttributes
            Resource: "*"
          - Sid:
              Fn::If:
                - SqsKmsKeyCustom
                - SourceEventRulesNoteKeyPolicyNeedsEventBridgeSqsKmsEncrypt
                - SourceEventRules
            Effect: Allow
            Principal: { Service: events.amazonaws.com }
            Action: sqs:SendMessage
            Resource: "*"
            Condition:
              ArnEquals:
                "aws:SourceArn":
                  - !GetAtt AuroraDbForcedStartToMainQueueRule.Arn
                  - !GetAtt RdsDbForcedStartToMainQueueRule.Arn
          - Sid:
              Fn::If:
                - SqsKmsKeyCustom
                - SourceQueueNoteKeyPolicyNeedsSqsKmsEncrypt
                - SourceQueue
            Effect: Allow
            Principal: "*"
            Action: sqs:SendMessage
            Resource: "*"
            Condition:
              ArnEquals:
                "aws:SourceArn":
                  - !GetAtt MainQueue.Arn
          - Sid: ExclusiveSources
            Effect: Deny
            Principal: "*"
            Action: sqs:SendMessage
            Resource: "*"
            Condition:
              ArnNotEquals:
                "aws:SourceArn":
                  - !GetAtt AuroraDbForcedStartToMainQueueRule.Arn
                  - !GetAtt RdsDbForcedStartToMainQueueRule.Arn
                  - !GetAtt MainQueue.Arn

  # Administrator: Block other invocation mechanisms
  LambdaFnInvokeLambdaPerm:
    Type: AWS::Lambda::Permission
    DependsOn: MainQueuePol
    Properties:
      Principal: sqs.amazonaws.com
      Action: lambda:InvokeFunction
      SourceArn: !GetAtt MainQueue.Arn
      FunctionName: !Ref LambdaFn

  AuroraDbForcedStartToMainQueueRule:
    Type: AWS::Events::Rule
    Properties:
      Description:
        Fn::If:
          - TestTrue
          - !Sub >-
              RDS-EVENT-0153 forced Aurora database cluster start after 7
              days,
              plus RDS-EVENT-0151 non-forced start for TEMPORARY TESTING,
              to ${MainQueue.QueueName}
          - !Sub >-
              RDS-EVENT-0153 forced Aurora database cluster start after 7
              days,
              to ${MainQueue.QueueName}
      EventPattern:
        source: [ aws.rds ]
        detail-type: [ RDS DB Cluster Event ]
        detail:
          EventID:

            - RDS-EVENT-0153
            # https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_Events.Messages.html#RDS-EVENT-0153
            # "DB cluster is being started due to it exceeding the maximum
            # allowed time being stopped."

            - !If [ TestTrue, RDS-EVENT-0151, !Ref AWS::NoValue ]
            # https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_Events.Messages.html#RDS-EVENT-0151
            # "DB cluster started."

          SourceType: [ CLUSTER ]
          SourceIdentifier:
            - anything-but:
                - ""
                # https://github.com/aws-cloudformation/cloudformation-coverage-roadmap/issues/1378
                # - null
        version: [ "0" ]
      Targets:
        - Id: !GetAtt MainQueue.QueueName
          Arn: !GetAtt MainQueue.Arn
          RetryPolicy:
            MaximumRetryAttempts: 10
            MaximumEventAgeInSeconds: 300  # 5 minutes
          DeadLetterConfig: { Arn: !GetAtt ErrorQueue.Arn }
      State: !If [ EnableTrue, ENABLED, DISABLED ]

  RdsDbForcedStartToMainQueueRule:
    Type: AWS::Events::Rule
    Properties:
      Description:
        Fn::If:
          - TestTrue
          - !Sub >-
              RDS-EVENT-0154 forced RDS database instance start after 7 days,
              plus RDS-EVENT-0088 non-forced start (ignored for instances in
              Aurora clusters) for TEMPORARY TESTING,
              to ${MainQueue.QueueName}
          - !Sub >-
              RDS-EVENT-0154 forced RDS database instance start after 7 days,
              to ${MainQueue.QueueName}
      EventPattern:
        source: [ aws.rds ]
        detail-type: [ RDS DB Instance Event ]
        detail:
          EventID:

            - RDS-EVENT-0154
            # https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.Messages.html#RDS-EVENT-0154
            # "DB instance is being started due to it exceeding the maximum
            # allowed time being stopped."

            - !If [ TestTrue, RDS-EVENT-0088, !Ref AWS::NoValue ]
            # https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.Messages.html#RDS-EVENT-0088
            # "DB instance started."
            #
            # Warning: Aurora database instances have an event that is
            # indistinguishable at this level. The Lambda function ignores it,
            # in assess_db_invalid_parameter .
            # https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_Events.Messages.html#RDS-EVENT-0088
            # "DB instance started."

          SourceType: [ DB_INSTANCE ]
          SourceIdentifier:
            - anything-but:
                - ""
                # https://github.com/aws-cloudformation/cloudformation-coverage-roadmap/issues/1378
                # - null
        version: [ "0" ]
      Targets:
        - Id: !GetAtt MainQueue.QueueName
          Arn: !GetAtt MainQueue.Arn
          RetryPolicy:
            MaximumRetryAttempts: 10
            MaximumEventAgeInSeconds: 300  # 5 minutes
          DeadLetterConfig: { Arn: !GetAtt ErrorQueue.Arn }
      State: !If [ EnableTrue, ENABLED, DISABLED ]

  MainQueue:
    Type: AWS::SQS::Queue
    Properties:
      DelaySeconds: 0
      SqsManagedSseEnabled: !If [ SqsKmsKeyBlank, true, false ]
      KmsMasterKeyId:
        Fn::If:
          - SqsKmsKeyBlank
          - !Ref AWS::NoValue
          - Fn::If:
              - SqsKmsKeyCustom
              - !Sub "arn:${AWS::Partition}:kms:${AWS::Region}:${SqsKmsKey}"
              - !Ref SqsKmsKey
      KmsDataKeyReusePeriodSeconds:
        !If [ SqsKmsKeyBlank, !Ref AWS::NoValue, 86400 ]  # seconds (24 hours)
      MaximumMessageSize: !Ref QueueMessageBytesMax

      MessageRetentionPeriod: !Ref ErrorQueueMessageRetentionPeriodSecs
      # Messages will be processed and deleted, or be moved to error (dead
      # letter) queue by QueueMaxReceiveCount * QueueVisibilityTimeoutSecs

      ReceiveMessageWaitTimeSeconds: 20  # long polling (lowest cost)
      VisibilityTimeout: !Ref QueueVisibilityTimeoutSecs
      RedrivePolicy:
        maxReceiveCount: !Ref QueueMaxReceiveCount
        deadLetterTargetArn: !GetAtt ErrorQueue.Arn
      RedriveAllowPolicy:
        redrivePermission: denyAll

  ErrorQueue:
    Type: AWS::SQS::Queue
    Properties:
      DelaySeconds: 0
      SqsManagedSseEnabled: !If [ SqsKmsKeyBlank, true, false ]
      KmsMasterKeyId:
        Fn::If:
          - SqsKmsKeyBlank
          - !Ref AWS::NoValue
          - Fn::If:
              - SqsKmsKeyCustom
              - !Sub "arn:${AWS::Partition}:kms:${AWS::Region}:${SqsKmsKey}"
              - !Ref SqsKmsKey
      KmsDataKeyReusePeriodSeconds:
        !If [ SqsKmsKeyBlank, !Ref AWS::NoValue, 86400 ]  # seconds (24 hours)

      MaximumMessageSize: !Ref QueueMessageBytesMax
      # Consider all sources of messages, not just MainQueue!

      MessageRetentionPeriod: !Ref ErrorQueueMessageRetentionPeriodSecs
      ReceiveMessageWaitTimeSeconds: 20  # long polling (lowest cost)
      VisibilityTimeout: 0  # seconds; dead message retries don't make sense

  LambdaFnLogGrp:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: !Ref LogRetentionInDays
      KmsKeyId:
        Fn::If:
          - CloudWatchLogsKmsKeyBlank
          - !Ref AWS::NoValue
          - !Sub "arn:${AWS::Partition}:kms:${AWS::Region}:${CloudWatchLogsKmsKey}"

  MainQueueToLambdaFnMapping:
    Type: AWS::Lambda::EventSourceMapping
    DependsOn: LambdaFnInvokeLambdaPerm
    Properties:
      EventSourceArn: !GetAtt MainQueue.Arn
      MaximumBatchingWindowInSeconds: 20  # long polling (lowest cost)
      BatchSize: !Ref LambdaFnBatchSize
      FunctionName: !GetAtt LambdaFn.Arn
      ScalingConfig:
        MaximumConcurrency: !Ref LambdaFnMaximumConcurrency
      FunctionResponseTypes:
        - ReportBatchItemFailures
      Enabled: !Ref Enable

  LambdaFn:
    Type: AWS::Lambda::Function
    Properties:
      Role: !GetAtt LambdaFnRole.Arn
      ReservedConcurrentExecutions:
        Fn::If:
          - LambdaFnReservedConcurrentExecutionsOff
          - !Ref AWS::NoValue
          - !Ref LambdaFnReservedConcurrentExecutions
      Timeout: !Ref LambdaFnTimeoutSecs
      MemorySize: !Ref LambdaFnMemoryMB
      LoggingConfig:
        LogGroup: !Ref LambdaFnLogGrp
        LogFormat: JSON
        SystemLogLevel: WARN
        ApplicationLogLevel: !Ref LogLevel
      TracingConfig: { Mode: PassThrough }
      Architectures:
        - arm64
      Runtime: python3.13
      Environment:
        Variables:
          "FOLLOW_UNTIL_STOPPED":
            !If [ FollowUntilStoppedTrue, "", !Ref AWS::NoValue ]
      Handler: index.lambda_handler
      Code:
        ZipFile: |
          #!/usr/bin/env python3
          """Stop AWS RDS and Aurora databases after the forced 7th-day start

          github.com/sqlxpert/stay-stopped-aws-rds-aurora  GPLv3  Copyright Paul Marcelin
          """

          from logging import getLogger, INFO, WARNING, ERROR
          from os import environ as os_environ
          from json import dumps as json_dumps, loads as json_loads
          from re import match as re_match
          from botocore.exceptions import ClientError as botocore_ClientError
          from botocore.config import Config as botocore_Config
          from boto3 import client as boto3_client

          logger = getLogger()
          # Skip "credentials in environment" INFO message, unavoidable in AWS Lambda:
          getLogger("botocore").setLevel(WARNING)

          FOLLOW_UNTIL_STOPPED = ("FOLLOW_UNTIL_STOPPED" in os_environ)  # pylint: disable=superfluous-parens


          def log(entry_type, entry_value, log_level):
            """Emit a JSON-format log entry
            """
            entry_value_out = json_loads(json_dumps(entry_value, default=str))
            # Avoids "Object of type datetime is not JSON serializable" in
            # https://github.com/aws/aws-lambda-python-runtime-interface-client/blob/9efb462/awslambdaric/lambda_runtime_log_utils.py#L109-L135
            #
            # The JSON encoder in the AWS Lambda Python runtime isn't configured to
            # serialize datatime values in responses returned by AWS's own Python SDK!
            #
            # Alternative considered:
            # https://docs.powertools.aws.dev/lambda/python/latest/core/logger/

            logger.log(
              log_level, "", extra={"type": entry_type, "value": entry_value_out}
            )


          def extract_db_cluster_state(error_msg):
            """Take an InvalidDBClusterStateFault error message, return cluster state

            None indicates state not found.

            Use "status" except in the context of parsing an Aurora
            InvalidDBClusterStateFault error message, which refers to "state".
            """
            db_cluster_state_re_match = re_match(
              r"DbCluster \S+ is in (?P<db_cluster_state>\S+) state", error_msg
            )
            return (
              db_cluster_state_re_match.group("db_cluster_state")
              if db_cluster_state_re_match else
              None
            )


          def get_db_instance_status(
            lambda_event, sqs_message, describe_db_instances_kwargs
          ):
            """Take describe_db_instances kwargs, return RDS database instance status

            None indicates an error.
            """
            log_level = ERROR
            db_instance_status = None

            method_name = "describe_db_instances"
            result = op_do(method_name, describe_db_instances_kwargs)
            if not isinstance(result, Exception):
              db_instances = result.get("DBInstances", [])
              if len(db_instances) == 1:
                db_instance_status = db_instances[0].get("DBInstanceStatus")
                if db_instance_status is not None:
                  log_level = INFO

            op_log(
              lambda_event,
              sqs_message,
              method_name,
              describe_db_instances_kwargs,
              result,
              log_level
            )

            return db_instance_status


          def assess_db_status(db_status):
            """Take database status, return log level and retry flag

            Focus is on statuses that temporarily or permanently preclude successfully
            requesting a database stop (i.e., not "available") and then on statuses
            through to a successful database stop.

            Aurora database cluster:
              https://docs.aws.amazon.com/en_us/AmazonRDS/latest/AuroraUserGuide/accessing-monitoring.html#Aurora.Status

            Aurora database instance (information only; instance status not assessed)
              https://docs.aws.amazon.com/en_us/AmazonRDS/latest/AuroraUserGuide/accessing-monitoring.html#Overview.DBInstance.Status

            RDS database instance:
              https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/accessing-monitoring.html#Overview.DBInstance.Status
            """
            log_level = ERROR
            retry = False

            if db_status is None:
              retry = True
              # Might be possible to determine status later

            else:
              match db_status.lower():
                # Unless noted, same status values (normalized to lower case) for
                # Aurora database cluster and RDS database instance.

                case "stopped" | "deleting" | "deleted":
                  log_level = INFO
                  # Terminal status, success!

                case (
                    "starting"  # Stop not yet successfully requested
                  | "stopping"  # Stop not yet confirmed
                  | "backing-up"
                  | "maintenance"
                  | "modifying"
                  | "renaming"
                  | "resetting-master-credentials"
                  | "storage-optimization"
                  | "upgrading"
                  # Aurora database cluster only:
                  | "backtracking"
                  | "failing-over"
                  | "migrating"
                  | "promoting"
                  | "update-iam-db-auth"
                  # RDS database instance only:
                  | "converting-to-vpc"
                  | "configuring-enhanced-monitoring"
                  | "configuring-iam-database-auth"
                  | "configuring-log-exports"
                  | "delete-precheck"
                  | "moving-to-vpc"
                  | "rebooting"
                  | "storage-config-upgrade"
                  | "storage-initialization"
                ):
                  log_level = INFO
                  retry = True
                  # Status will probably change

                case (
                    "inaccessible-encryption-credentials-recoverable"
                  # RDS database instance only:
                  | "incompatible-network"
                  | "incompatible-option-group"
                  | "incompatible-parameters"
                ):
                  retry = True
                  # Status might change, but log as ERROR

                case (
                    "inaccessible-encryption-credentials"
                  # Aurora database cluster only:
                  | "cloning-failed"
                  | "migration-failed"
                  | "preparing-data-migration"
                  # RDS database instance only:
                  | "failed"
                  | "incompatible-restore"
                  | "insufficient-capacity"
                  | "restore-error"
                  | "storage-full"
                ):
                  pass
                  # Status won't change; listing recognized no-retry ERROR conditions

            return (log_level, retry)


          def assess_db_invalid_parameter(error_message):
            """Take InvalidParameterCombination message, return log level and retry flag
            """
            log_level = ERROR
            retry = False

            if (
              ("aurora" in error_message)
              and ("not eligible for stopping" in error_message)
            ):
              log_level = INFO
              # Quietly ignore database instance start events for Aurora,
              # https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_Events.Messages.html#RDS-EVENT-0088
              #
              # ...because there will be a corresponding database cluster event,
              # https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_Events.Messages.html#RDS-EVENT-0151
              #
              # ...and Aurora database instances cannot be stopped independently of
              # their Aurora cluster, per:
              # https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-cluster-stop-start.html#aurora-cluster-start-stop-overview
              #
              # This case occurs only in test mode. At the EventPattern level (see
              # CloudFormation), the start event for Aurora database instances is
              # indistinguishable from the start event for RDS database instances,
              # https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.Messages.html#RDS-EVENT-0088

            return (log_level, retry)


          def assess_stop_db_exception(
            lambda_event,
            sqs_message,
            source_type_word,
            misc_exception,
            describe_db_instances_kwargs
          ):
            """Take a boto3 exception, return log level and retry flag

            ClientError is general but statically-defined, making comparison
            easier than for RDS-specific but dynamically-defined exceptions...

            RDS-specific exception name:  ClientError code:
            InvalidDBClusterStateFault    InvalidDBClusterStateFault
            InvalidDBInstanceStateFault   InvalidDBInstanceState (Fault suffix missing!)

            https://boto3.amazonaws.com/v1/documentation/api/latest/guide/error-handling.html#parsing-error-responses-and-catching-exceptions-from-aws-services
            """
            log_level = ERROR
            retry = False

            if isinstance(misc_exception, botocore_ClientError):
              error_dict = getattr(misc_exception, "response", {}).get("Error", {})
              error_message = error_dict.get("Message", "")
              match error_dict.get("Code"):

                case "InvalidDBClusterStateFault":
                  db_status = extract_db_cluster_state(error_message)
                  (log_level, retry) = assess_db_status(db_status)

                case "InvalidDBInstanceState" if source_type_word == "INSTANCE":  # RDS
                  db_status = get_db_instance_status(
                    lambda_event, sqs_message, describe_db_instances_kwargs
                  )
                  (log_level, retry) = assess_db_status(db_status)

                case "InvalidDBInstanceState":  # Aurora
                  # Status of this and any other cluster members will probably change
                  log_level = INFO
                  retry = True

                case "InvalidParameterCombination":
                  (log_level, retry) = assess_db_invalid_parameter(error_message)

            return (log_level, retry)


          rds_client = None  # pylint: disable=invalid-name


          def rds_client_get():
            """Return a boto3 RDS client, creating it if needed

            boto3 method references can only be resolved at run-time, against an
            instance of an AWS service's Client class.
            http://boto3.readthedocs.io/en/latest/guide/events.html#extensibility-guide

            Alternatives considered:
            https://github.com/boto/boto3/issues/3197#issue-1175578228
            https://github.com/aws-samples/boto-session-manager-project
            """
            global rds_client  # pylint: disable=global-statement
            if not rds_client:
              rds_client = boto3_client(
                "rds", config=botocore_Config(retries={"mode": "standard"})
              )
            return rds_client


          def op_do(op_method_name, op_kwargs):
            """Take a boto3 method name and kwargs, return response or exception
            """
            try:
              op_method = getattr(rds_client_get(), op_method_name)
              op_result = op_method(**op_kwargs)
            except Exception as misc_exception:  # pylint: disable=broad-exception-caught
              op_result = misc_exception
            return op_result


          def op_log(  # pylint: disable=too-many-arguments,too-many-positional-arguments
            lambda_event, sqs_message, op_method_name, op_kwargs, result, log_level
          ):
            """Log Lambda event, batch message, boto3 method, kwargs, exception/response

            op_log() is separate from op_do() so that log_level can be decided later:
            - A result originally logged as INFO can be re-logged as an ERROR after a
              downstream error occurs.
            - An expected exception can be logged as INFO instead of an ERROR.
            """
            if log_level > INFO:
              log("LAMBDA_EVENT", lambda_event, log_level)
              log("SQS_MESSAGE", sqs_message, log_level)
            if op_method_name:
              log(f"{op_method_name.upper()}_KWARGS", op_kwargs, log_level)
            log(
              "EXCEPTION" if isinstance(result, Exception) else "AWS_RESPONSE",
              result,
              log_level
            )


          def lambda_handler(lambda_event, context):  # pylint: disable=unused-argument
            """Try to request stopping Aurora database clusters, RDS database instances

            Called in response to a batch of forced database start events (see
            EventPattern in CloudFormation) stored as messages in the main SQS queue.

            Batch item failure:
              Event message remains in main queue. Retry after VisibilityTimeout ,
              in hopes that database status will change. After maxReceiveCount (see
              CloudFormation) total tries, message goes to error (dead letter) queue.

            Batch item success:
              Event message is deleted from main queue. Do not retry, because:
                1. Database was already stopped, deleted, or being deleted, or
                2. It was not possible to request stopping, due to:
                   a. An unexpected error while trying
                      (boto3 handles transient errors; see retries config parameter)
                   b. An abnormal database status that won't change or is unfamiliar
            """
            log("LAMBDA_EVENT", lambda_event, INFO)
            batch_item_failures = []

            for sqs_message in lambda_event.get("Records", []):
              log("SQS_MESSAGE", sqs_message, INFO)
              sqs_message_id = ""

              method_name = ""
              stop_db_kwargs = {}
              result = None
              log_level = INFO
              retry = FOLLOW_UNTIL_STOPPED

              try:
                sqs_message_id = sqs_message["messageId"]
                db_event = json_loads(sqs_message["body"])
                db_event_detail = db_event["detail"]
                # Events have "CLUSTER" (Aurora) or "DB_INSTANCE" (RDS); take last word:
                source_type_word = db_event_detail["SourceType"].split("_")[-1]
                source_identifier = db_event_detail["SourceIdentifier"]

                method_name = f"stop_db_{source_type_word.lower()}"
                stop_db_kwargs = {
                  f"DB{source_type_word.title()}Identifier": source_identifier,
                }
                result = op_do(method_name, stop_db_kwargs)
                if isinstance(result, Exception):
                  (log_level, retry) = assess_stop_db_exception(
                    lambda_event, sqs_message, source_type_word, result, stop_db_kwargs
                  )

              except Exception as misc_exception:  # pylint: disable=broad-exception-caught
                result = misc_exception
                log_level = ERROR
                retry = False

              op_log(
                lambda_event,
                sqs_message,
                method_name,
                stop_db_kwargs,
                result,
                log_level
              )

              if retry and sqs_message_id:
                batch_item_failures.append({"itemIdentifier": sqs_message_id})

            # https://repost.aws/knowledge-center/lambda-sqs-report-batch-item-failures
            return {"batchItemFailures": batch_item_failures}
